# Gradiente Estocástico

No **Batch gradient descent** (descida do gradiente tradicional) ele vai calcular o erro para todos os registro e vai atualizar os pesos.

Nessa outra forma chamada **Stochastic gradient descent** - **SGD** ao invés de selecionar a minha base de dados inteira eu
estou selecionando somente uma parte da base de dados, então eu seleciono
uma parte e calculo o erro e faço a atualização do peso para essa linha.

![alt text](../imagens/gradiente2/ex1.png)

## Decida do gradiente estocástica

- Ajuda a prevenir mínimos locais (superfícies não convexas)
- Mais rápido (não precisa carregar todos os dados em memória)

## Mini batch gradient descent

- Escolhe um número de registros para rodar e atualizar os pesos

Aqui eu coloco quantos registros que eu quero que ele selecione para
fazer a atualização do pesos.
